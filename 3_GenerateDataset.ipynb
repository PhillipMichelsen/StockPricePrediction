{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HSA_OVERRIDE_GFX_VERSION=10.3.0\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "%env HSA_OVERRIDE_GFX_VERSION=10.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Classes import StockData\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "PROCESSED_DATA_DIRECTORY = 'Data/Processed/Stock'\n",
    "DATASET_DIRECTORY = 'Data/Datasets/Stock_100'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "files = os.listdir(PROCESSED_DATA_DIRECTORY)\n",
    "batched_files = [files[i:i+5] for i in range(0, len(files), 5)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forex30_5.1 | ['Processed_63', 'Processed_45', 'Processed_90', 'Processed_58', 'Processed_60']\n",
      "Forex30_5.2 | ['Processed_4', 'Processed_26', 'Processed_35', 'Processed_30', 'Processed_50']\n",
      "Forex30_5.3 | ['Processed_88', 'Processed_32', 'Processed_97', 'Processed_72', 'Processed_19']\n",
      "Forex30_5.4 | ['Processed_28', 'Processed_48', 'Processed_11', 'Processed_84', 'Processed_22']\n",
      "Forex30_5.5 | ['Processed_44', 'Processed_65', 'Processed_95', 'Processed_91', 'Processed_52']\n",
      "Forex30_5.6 | ['Processed_40', 'Processed_51', 'Processed_98', 'Processed_55', 'Processed_99']\n",
      "Forex30_5.7 | ['Processed_39', 'Processed_57', 'Processed_41', 'Processed_92', 'Processed_78']\n",
      "Forex30_5.8 | ['Processed_2', 'Processed_96', 'Processed_66', 'Processed_3', 'Processed_93']\n",
      "Forex30_5.9 | ['Processed_100', 'Processed_59', 'Processed_14', 'Processed_76', 'Processed_36']\n",
      "Forex30_5.10 | ['Processed_16', 'Processed_70', 'Processed_8', 'Processed_42', 'Processed_27']\n",
      "Forex30_5.11 | ['Processed_61', 'Processed_68', 'Processed_56', 'Processed_80', 'Processed_15']\n",
      "Forex30_5.12 | ['Processed_74', 'Processed_1', 'Processed_64', 'Processed_87', 'Processed_94']\n",
      "Forex30_5.13 | ['Processed_54', 'Processed_34', 'Processed_25', 'Processed_71', 'Processed_6']\n",
      "Forex30_5.14 | ['Processed_62', 'Processed_89', 'Processed_18', 'Processed_81', 'Processed_5']\n",
      "Forex30_5.15 | ['Processed_37', 'Processed_73', 'Processed_24', 'Processed_77', 'Processed_21']\n",
      "Forex30_5.16 | ['Processed_7', 'Processed_13', 'Processed_9', 'Processed_82', 'Processed_29']\n",
      "Forex30_5.17 | ['Processed_38', 'Processed_43', 'Processed_85', 'Processed_10', 'Processed_46']\n",
      "Forex30_5.18 | ['Processed_20', 'Processed_53', 'Processed_83', 'Processed_33', 'Processed_75']\n",
      "Forex30_5.19 | ['Processed_47', 'Processed_79', 'Processed_49', 'Processed_86', 'Processed_23']\n",
      "Forex30_5.20 | ['Processed_17', 'Processed_69', 'Processed_67', 'Processed_31', 'Processed_12']\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(batched_files):\n",
    "    current_batch_dataset = []\n",
    "    for file in batch:\n",
    "        stockFile = pd.read_csv(f'{PROCESSED_DATA_DIRECTORY}/{file}', index_col=0)\n",
    "        stockFile.astype(float)\n",
    "        current_batch_dataset.append(StockData(stockFile))\n",
    "\n",
    "    current_batch_dataset = torch.utils.data.ConcatDataset(current_batch_dataset)\n",
    "    torch.save(current_batch_dataset, f'{DATASET_DIRECTORY}/Stock100_5.{i+1}.pt')\n",
    "    print(f'Forex30_5.{i+1} | {batch}')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

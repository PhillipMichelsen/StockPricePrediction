{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-25T15:33:50.150987822Z",
     "start_time": "2023-05-25T15:33:47.005699610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HSA_OVERRIDE_GFX_VERSION=10.3.0\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "%env HSA_OVERRIDE_GFX_VERSION=10.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from Classes import ConvLSTM\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "TRAIN_DATASETS = 'Test/'\n",
    "TEST_DATASET_FILE = 'Stock100_10.11.pt'\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "MODEL_NAME = 'work_please'\n",
    "LATEST_MODEL_VERSION = 'BASE.pt'\n",
    "CURRENT_MODEL_EPOCHS = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T15:34:26.012968762Z",
     "start_time": "2023-05-25T15:33:50.126112049Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "test_dataset = torch.load('Data/Datasets/Stock_100/MASTER.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T15:36:47.690663522Z",
     "start_time": "2023-05-25T15:34:26.053718678Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 15, 90])\n",
      "torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "conv_layer = nn.Conv1d(15, 32, kernel_size=3, device='cuda')\n",
    "x = torch.randn(32, 15, 90).to('cuda')\n",
    "print(x.size())\n",
    "print(x.type())\n",
    "y = conv_layer(x)\n",
    "print(y.size())\n",
    "print(y.type())"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-05-25T14:41:11.833583669Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model_params = {}\n",
    "\n",
    "with open(f'Models/{MODEL_NAME}/params.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        key, value = line.split(\": \")\n",
    "        if key in ['input_length', 'input_features', 'output_length', 'output_features',\n",
    "                   'kernel_size', 'batch_size']:\n",
    "            model_params[key] = int(value)\n",
    "        elif key in ['conv_hidden_sizes', 'lstm_hidden_sizes']:\n",
    "            # Removing brackets and spaces, then converting to int\n",
    "            model_params[key] = list(map(int, value.replace('[','').replace(']','').replace(' ','').split(',')))\n",
    "        else: # it's a string (model_name)\n",
    "            model_params[key] = value.strip()  # .strip() to remove newline characters"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T14:05:23.105893477Z",
     "start_time": "2023-05-25T14:05:23.100991469Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters as follows:\n",
      "Input shape - (90,15)\n",
      "Output shape - (1,1)\n",
      "----------------------------------\n",
      "Conv hidden sizes - [32, 64]\n",
      "LSTM hidden sizes - [128, 128]\n",
      "Kernel size - 3\n",
      "Batch size - 32\n"
     ]
    }
   ],
   "source": [
    "print('Model parameters as follows:')\n",
    "print(f'Input shape - ({model_params[\"input_length\"]},{model_params[\"input_features\"]})')\n",
    "print(f'Output shape - ({model_params[\"output_length\"]},{model_params[\"output_features\"]})')\n",
    "print('----------------------------------')\n",
    "print(f'Conv hidden sizes - {model_params[\"conv_hidden_sizes\"]}')\n",
    "print(f'LSTM hidden sizes - {model_params[\"lstm_hidden_sizes\"]}')\n",
    "print(f'Kernel size - {model_params[\"kernel_size\"]}')\n",
    "print(f'Batch size - {model_params[\"batch_size\"]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T14:05:24.418629415Z",
     "start_time": "2023-05-25T14:05:24.401753469Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T14:05:38.301716568Z",
     "start_time": "2023-05-25T14:05:38.298415690Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\nConvLSTM                                 --\n├─ModuleList: 1-1                        --\n│    └─Conv1d: 2-1                       1,472\n│    └─Conv1d: 2-2                       6,208\n├─ModuleList: 1-2                        --\n│    └─LSTM: 2-3                         99,328\n│    └─LSTM: 2-4                         132,096\n├─Conv1d: 1-3                            1,472\n├─Linear: 1-4                            129\n├─Dropout: 1-5                           --\n=================================================================\nTotal params: 240,705\nTrainable params: 240,705\nNon-trainable params: 0\n================================================================="
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvLSTM(input_features=model_params['input_features'],\n",
    "                 conv_hidden_sizes=model_params['conv_hidden_sizes'],\n",
    "                 lstm_hidden_sizes=model_params['lstm_hidden_sizes'],\n",
    "                 kernel_size=model_params['kernel_size'],\n",
    "                 output_features=model_params['output_features']\n",
    "                 )\n",
    "model.load_state_dict(torch.load(f'Models/{MODEL_NAME}/{LATEST_MODEL_VERSION}'))\n",
    "model.to(device)\n",
    "summary(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T14:05:41.717914606Z",
     "start_time": "2023-05-25T14:05:38.301371474Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Stock100_10.11.pt !!!\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "\n",
    "for concat_dataset in os.listdir(f'Data/Datasets/{TRAIN_DATASETS}'):\n",
    "    dataset = torch.load(f'Data/Datasets/{TRAIN_DATASETS}/{concat_dataset}')\n",
    "    datasets.extend(dataset.datasets)\n",
    "    print(f'Loaded {concat_dataset} !!!')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T14:05:51.328913189Z",
     "start_time": "2023-05-25T14:05:49.550234597Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.ConcatDataset(datasets)\n",
    "test_dataset = torch.load(f'Data/Datasets/Test/{TEST_DATASET_FILE}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T14:06:00.710356638Z",
     "start_time": "2023-05-25T14:05:59.981903612Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=model_params[\"batch_size\"],shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=model_params[\"batch_size\"],shuffle=False, drop_last=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T14:06:00.712557183Z",
     "start_time": "2023-05-25T14:06:00.710989339Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "epoch_times = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T14:06:01.802647272Z",
     "start_time": "2023-05-25T14:06:01.799691062Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Training!!! -----\n",
      "Inputs shape: torch.Size([32, 90, 15])\n",
      "Trying defined conv\n",
      "SUCCESS!!! Temp shape: torch.Size([32, 32, 88])\n",
      "Zero grad!!!\n",
      "Before transpotition:  torch.Size([32, 90, 15])\n",
      "After transpotition:  torch.Size([32, 15, 90])\n",
      "torch.Size([32, 15, 90])\n",
      "torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    train_loss = 0\n",
    "\n",
    "    # Train for epoch\n",
    "    model.train()\n",
    "    for inputs, targets in train_dataloader:\n",
    "        inputs, targets = inputs.float().to(device), targets.float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).float()\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Evaluate for epoch\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        model.eval()\n",
    "\n",
    "        for inputs, targets in test_dataloader:\n",
    "            print('Testing!!!')\n",
    "            inputs, targets = inputs.float().to(device), targets.float().to(device)\n",
    "\n",
    "            outputs = model(inputs).float()\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            print(f'Loss: {loss.item()}')\n",
    "\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "    epoch_times.append(epoch_time)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Train Loss: {train_loss:.8f}, Test Loss: {test_loss:.8f} | Time taken: {epoch_time:.1f} seconds\")\n",
    "\n",
    "    torch.save(model.state_dict(), f'Models/{MODEL_NAME}/{MODEL_NAME}_epoch_{CURRENT_MODEL_EPOCHS+epoch+1}.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-25T14:06:09.841346318Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(test_losses)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-25T11:16:44.326581763Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
